{"cells":[{"cell_type":"markdown","metadata":{"id":"SgNZTjrhcHa0"},"source":["## Homework 1, CS685 Spring 2023\n","\n","### This is due on April 5th, 2023. This notebook is to be submitted via Gradescope as a PDF file, while your three dataset files (annotator1.csv, annotator2.csv, and final_data.csv) should be emailed to cs685instructors@gmail.com with the subject line formatted as **Firstname_Lastname_HW1data**. 100 points total.\n","\n","#### IMPORTANT: After copying this notebook to your Google Drive, please paste a link to it below. To get a publicly-accessible link, hit the *Share* button at the top right, then click \"Get shareable link\" and copy over the result. If you fail to do this, you will receive no credit for this homework!\n","***LINK:***\n","\n","---\n","\n","\n","##### *How to submit this problem set:*\n","- Write all the answers in this Colab notebook. Once you are finished, generate a PDF via (File -> Print -> Save as PDF) and upload it to Gradescope.\n","  \n","- **Important:** check your PDF before you submit to Gradescope to make sure it exported correctly. If Colab gets confused about your syntax, it will sometimes terminate the PDF creation routine early.\n","\n","- **Important:** on Gradescope, please make sure that you tag each page with the corresponding question(s). This makes it significantly easier for our graders to grade submissions, especially with the long outputs of many of these cells. We will take off points for submissions that are not tagged.\n","\n","- When creating your final version of the PDF to hand in, please do a fresh restart and execute every cell in order. One handy way to do this is by clicking `Runtime -> Run All` in the notebook menu.\n","\n","---\n","\n","##### *Academic honesty*\n","\n","- We will audit the Colab notebooks from a set number of students, chosen at random. The audits will check that the code you wrote actually generates the answers in your PDF. If you turn in correct answers on your PDF without code that actually generates those answers, we will consider this a serious case of cheating. See the course page for honesty policies.\n","\n","- We will also run automatic checks of Colab notebooks for plagiarism. Copying code from others is also considered a serious case of cheating.\n","\n","- There is no penalty for using AI assistance on this homework as long as you fully disclose it in the final cell of this notebook (this includes storing any prompts that you feed to large language models). That said, anyone caught using AI assistance without proper disclosure will receive a zero on the assignment (we have several automatic tools to detect such cases). We're literally allowing you to use it with no limitations, so there is no reason to lie!\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"r2dYC4HbZL-j"},"source":["# Part 1: Annotation\n","\n","In this homework, you will first collect a labeled dataset of **120** sentences for a text classification task of your choice. This process will include:\n","\n","1. *Data collection*: Collect 120 sentences from any source you find interesting (e.g., literature, Tweets, news articles, reviews, etc.)\n","\n","2. *Task design*: Come up with a binary (i.e., only two labels) sentence-level classification task that you would like to perform on your sentences. Be creative, and make sure your task isn't too easy (e.g., perhaps the labels have some degree of subjectivity to them, or the task is otherwise complex for humans). Write up annotator guidelines/instructions on how you would like people to label your data.\n","\n","3. On your dataset, collect annotations from **two** classmates for your task. Everyone in this class will need to both create their own dataset and also serve as an annotator for two other classmates. In order to get everything done on time, you need to complete the following steps:\n","\n","> *   Find two classmates willing to label 120 sentences each (use the Piazza \"search for teammates\" thread if you're having issues finding labelers).\n","*   Send them your annotation guidelines and a way that they can easily annotate the data (e.g., a spreadsheet or Google form)\n","*   Collect the labeled data from each of the two annotators.\n","*   Sanity check the data for basic cleanliness (are all examples annotated? are all labels allowable ones?)\n","\n","4. Collect feedback from annotators about the task including annotation time and obstacles encountered (e.g., maybe your guidelines were confusing! or maybe some sentences were particularly hard to annotate!)\n","\n","5. Calculate and report inter-annotator agreement.\n","\n","6. Aggregate output from both annotators to create final dataset.\n","\n","7. Perform NLP experiments on your new dataset!"]},{"cell_type":"markdown","metadata":{"id":"Heui1z3IjZh_"},"source":["## Question 1.1 (10 points):\n","Describe the source of your unlabeled data, why you chose it, and what kind of sentence selection process you used (if any) to choose 120 sentences for annotation. Also briefly describe the text classification task that you will be collecting labels for in the next section.\n","\n","**Answer:** \\\\\n","###**Description of the Dataset** \n","Grinding Leetcode - solving coding problems is no longer an unfamiliar thing to CS students who want to break into the industry and work for big tech companies. When solving coding problems, we often focus on the questions’ pattern, therefore correctly categorize them could help us efficiently allocate the time to approach the optimal solution.\n","\n","\\\\\n","The dataset contains 120 problems taken from different platforms such as Leetcode, Hacker, Codeforces etc. Despite the fact that most problems have the label given by the platform, they are mostly categorized based on the rubrics of the platforms instead of candidates' experience. The could a combination of time and space complexity contraints, implementability of the solution etc. \n","\n","\\\\\n","However, I and including many more often agree that time complexity is the most important constaint during interviews. Thus, additional to the problem description there is time complexity required. Thus I consider these as unlabeled data. An important note that coding problems can be telling stories, thus I will only choose problems that are directly correlated to Computer Science field. Each entry in the dataset contains the description of the problem and a time complexity in terms of big-O notation concatenated at the end.\n","\n","\\\\\n","###**Data Scraping Process**\n","120 questions are randomly picked from previous mentioned sources. Some problems I decided to relax the time constraint, some I did not. Thus in the dataset, it is possible that there are problems that appear multiple times, however the time complexity constraint is totally different to each other. In other words a coding problem can have a variety of difficulties\n","\n","\\\\\n","###**Classification Task**\n","The goal of this task is to classify if a coding problem given a big-O time complexity constraint is categorized as easy or not. The term “Easy” refers to whether a solution that meets the required time complexity constraint can be come up by the candidate within 5 minutes.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EynpTLydj7IM"},"source":["## Question 1.2 (25 points):\n","Copy the annotation guidelines that you provided to your classmates below. We expect that these guidelines will be very detailed (and as such could be fairly long). You must include:\n","\n","> *   The two categories for your binary classification problem, including the exact strings you want annotators to use while labeling. \n","*   Descriptions of the categories and what they mean.\n","*   Representative examples of each category (i.e., sentences from outside your dataset that you have manually labeled to give annotators an idea of how to perform the task)\n","*   A discussion of of tricky corner cases, and criteria to help the annotator decide them. If you look at the data and think about how an annotator could do the task, you will likely find a bunch of these!\n","\n","\n","---\n","\n","\n","\n","\n","### *COPY YOUR ANNOTATION GUIDELINES HERE.* Please format them nicely so it's easy for us to read / grade :)### \n","\n","###**Annotation Guidelines**\n","\n","\n","*   Read the tweet thoroughly and understand its context before making a decision.\n","*   Assign a label of:\n"," * 1 (Easy)- if you think the solution for the given problem can be come up within 5 minutes that meet the time complexity required and\n"," * 0 (Difficult) - if otherwise.\n","\n","  **NOTE**: There are problems that appear multiple times, however the time complexity constraint on each is totally different.\n","\n","* If you are unsure, take a look at the requirement for the time complexity constraint of the problem and make a decision. If you still remain unsure, assign 0.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"935duWappc-o"},"source":["## Question 1.3 (5 points):\n","Write down the names and emails of the two classmates who will be annotating your data below. Once they are finished annotating, create two .csv files (annotator1.csv and annotator2.csv) that contains each annotator's labels. The file should have two columns with headers **text** and **label**, respectively. You will include these files in an email to the instructors account when you're finished with this homework. \n","\n","*The tweets.csv file provided as an example in Part 2 below uses the same format.*\n","\n","### *WRITE CLASSMATE 1 NAME/EMAIL HERE:* achauhan@umass.edu###\n","### *WRITE CLASSMATE 2 NAME/EMAIL HERE:* saranathkann@umass.edu###"]},{"cell_type":"markdown","metadata":{"id":"bcIMegO_uPRK"},"source":["## Question 1.4 (10 points):\n","After both annotators have finished labeling the 120 sentences you gave them, ask them for feedback about your task and the provided annotation guidelines. If you were to collect more labeled data for this task in the future, what would you change from your current setup? Why? Please include a summary of annotator feedback (with specific examples that they found challenging to label) in your answer.\n","\n","### *WRITE ANSWER HERE* ###\n","\n","**Anshumaan's feedback:**\n","I found the problem pretty interesting, this could help companes such as LeetCode, HackerRank, and many others to rank their problems much more efficiently due to the human feedback. There were some problems I was unfamiliar of and therefore even if the time complexity allowed was huge, I marked them as 0. I found the annotations pretty interesting and I have also marked one of the case where people would fall into the trap of categorizing an easy problem as a difficult one just beacuse of the phrasing. I also found problem 10 (row 11 in the sheet) misleading as they have rephrased bucket sort in fancy manner.\n","\n","\\\\\n","\n","**Saranath's feedback:** None\n","\n","\\\\\n","\n","If I were to collect more labeled data I would still probably keep the current setup since the labeled data are potentially categorized differently than how I labeled the data. In fact this situation is similar to the sources of data and how I collected dataset at the moment. However to label the data, I should make sure my annotators are comfortable to solving technical Leetcode-styled questions.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4ltte0Z-vD0u"},"source":["## Question 1.5 (10 points):\n","Now, compute the inter-annotator agreement between your two annotators. Upload both .csv files to your Colab session (click the folder icon in the sidebar to the left of the screen). In the code cell below, read the data from the two files and compute both the raw agreement (% of examples for which both annotators agreed on the label) and the [Cohen's Kappa](https://en.wikipedia.org/wiki/Cohen%27s_kappa). Feel free to use implementations in existing libraries (e.g., [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html)). After you're done, paste the numbers in the text cell that follows your code. \n","\n","*If you're curious, Cohen suggested the Kappa result be interpreted as follows: values ≤ 0 as indicating no agreement and 0.01–0.20 as none to slight, 0.21–0.40 as fair, 0.41– 0.60 as moderate, 0.61–0.80 as substantial, and 0.81–1.00 as almost perfect agreement.*"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"SmA-4ItUILDo","executionInfo":{"status":"ok","timestamp":1680812603209,"user_tz":240,"elapsed":22804,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"efac7a02-4e04-4b67-d4af-a236fbcccfe1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1X2KyUZFUSLb9d_BgMordzGuuqI57jMn_/CS685 Advanced NLP\n"]}],"source":["# Run this only when you need to use Google Colab VM\n","# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n","FOLDERNAME = 'CS685 Advanced NLP'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","%cd /content/drive/My\\ Drive/$FOLDERNAME"]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"jMLcQhUiPIHi","executionInfo":{"status":"ok","timestamp":1680812604065,"user_tz":240,"elapsed":863,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"ff42fd62-2445-4704-ae8d-c2ce3200c54b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":[" Anshumaan.csv\t\t\t\t    Dataset_HW1.xlsx\n"," CS685_HW0_S23.ipynb\t\t\t    final_data.csv\n","'[CS685] [HW1] Annotation Guideline.docx'   final_dataset.csv\n"," CS685_S23_HW1.ipynb\t\t\t    helpers.py\n"," Dataset_Clearning.ipynb\t\t    __pycache__\n"," Dataset_HW1_Annotation_Anshumaan.xlsx\t    Saranath.csv\n"," Dataset_HW1_Annotation_Saranath.xlsx\t    tweets.csv\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"BWkt6u-IKp77","executionInfo":{"status":"ok","timestamp":1680812605002,"user_tz":240,"elapsed":942,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import cohen_kappa_score"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"UD7yvkwgy82S","executionInfo":{"status":"ok","timestamp":1680812605495,"user_tz":240,"elapsed":498,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["### WRITE CODE TO LOAD ANNOTATIONS AND \n","### COMPUTE AGREEMENT + COHEN'S KAPPA HERE!\n","df_anshumaan = pd.read_csv('Anshumaan.csv')\n","df_saranath = pd.read_csv('Saranath.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"TLnCQ8b0Maaz","outputId":"709e6b99-c108-4dde-e5ae-7d53c28f67bd","executionInfo":{"status":"ok","timestamp":1680812605495,"user_tz":240,"elapsed":19,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Problem Description and Time Complexity required  Label\n","0           Check if a given sudoku is valid. O(N^2)      0\n","1  Merge the two lists in a one sorted list. The ...      1\n","2  Given the root of a binary tree, invert the tr...      1\n","3  Given the head of a sorted linked list, delete...      1\n","4  Given two binary strings a and b, return their...      1"],"text/html":["\n","  <div id=\"df-b351b185-e0db-468e-b1be-60202b57d6f3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Problem Description and Time Complexity required</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Check if a given sudoku is valid. O(N^2)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Merge the two lists in a one sorted list. The ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Given the root of a binary tree, invert the tr...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Given the head of a sorted linked list, delete...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Given two binary strings a and b, return their...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b351b185-e0db-468e-b1be-60202b57d6f3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b351b185-e0db-468e-b1be-60202b57d6f3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b351b185-e0db-468e-b1be-60202b57d6f3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["df_anshumaan.head(5)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"VMGy4rnxMZKW","outputId":"fe4c4357-3267-45cb-e273-bd488a98bed0","executionInfo":{"status":"ok","timestamp":1680812605496,"user_tz":240,"elapsed":17,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Problem Description and Time Complexity required  Label\n","0           Check if a given sudoku is valid. O(N^2)      1\n","1  Merge the two lists in a one sorted list. The ...      1\n","2  Given the root of a binary tree, invert the tr...      0\n","3  Given the head of a sorted linked list, delete...      1\n","4  Given two binary strings a and b, return their...      1"],"text/html":["\n","  <div id=\"df-e1361daa-c0ce-47af-bebb-c05ab52ac346\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Problem Description and Time Complexity required</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Check if a given sudoku is valid. O(N^2)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Merge the two lists in a one sorted list. The ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Given the root of a binary tree, invert the tr...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Given the head of a sorted linked list, delete...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Given two binary strings a and b, return their...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1361daa-c0ce-47af-bebb-c05ab52ac346')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e1361daa-c0ce-47af-bebb-c05ab52ac346 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e1361daa-c0ce-47af-bebb-c05ab52ac346');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["df_saranath.head(5)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"aTEuNm3JMM7d","outputId":"c197fa67-c5ff-4af6-b4b3-8eeaef7aecf5","executionInfo":{"status":"ok","timestamp":1680812605497,"user_tz":240,"elapsed":16,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Raw agreement (% of labels that both annotators agree on): 0.66\n"]}],"source":["labels_anshumaan = df_anshumaan['Label'].to_numpy()\n","labels_saranath = df_saranath['Label'].to_numpy()\n","\n","agreement = ((labels_anshumaan == labels_saranath).sum()) / labels_anshumaan.size\n","print('Raw agreement (% of labels that both annotators agree on): {:.2f}'.format(agreement))"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"MQ9EoCgON8kk","outputId":"6d4e2413-a247-4aab-e6ad-0fc5946de90a","executionInfo":{"status":"ok","timestamp":1680812605497,"user_tz":240,"elapsed":13,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cohen Kappa score between 2 annotators: 0.28\n"]}],"source":["ck_score = cohen_kappa_score(labels_anshumaan, labels_saranath)\n","print('Cohen Kappa score between 2 annotators: {:.2f}'.format(ck_score))"]},{"cell_type":"markdown","metadata":{"id":"Qd7Xq4SKzF5U"},"source":["###*RAW AGREEMENT*: 0.66\n","###*COHEN'S KAPPA*: 0.28"]},{"cell_type":"markdown","metadata":{"id":"t2-1LkRHze5N"},"source":["## Question 1.6 (10 points):\n","To form your final dataset, you need to *aggregate* the annotations from both annotators (i.e., for cases where they disagree, you need to choose a single label). Use any method you like other than random label selection to perform this aggregation (e.g., have the two annotators discuss each disagreement and come to consensus, or choose the label you agree with the most). Upload your final dataset to the Colab session (in the same format as the other two files) as final_dataset.csv. Remember to include this file in your final email to us!\n","\n","### *DESCRIBE YOUR AGGREGATION STRATEGY HERE* ###\n","To generate the aggregate both annotators' labels to generate the final dataset I simply use the min function between 2 labels:\n","\n","$$\\boxed{\\text{label}_{i} = \\text{min}(\\text{label}_{\\text{Anshumaan}, \\text{ }i}, \\text{ }\\text{label}_{\\text{Saranath}, \\text{ }i})}$$\n","\n","\\\\\n","In other words, if either one annotator finds a problem difficult (label 0) then we should assign label 0 to that corresponding problem. If an annotator A comes up with solution withint 5 minutes and annotator B comes up with solution more than 5 minutes then it is also possible for annotator A to come up with solution more than 5 minutes. It means that if a problem is difficult for 1 annotator, then it can be difficult for both annotator but not the other way around.\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Nx0HZH2WfTMJ","executionInfo":{"status":"ok","timestamp":1680812605498,"user_tz":240,"elapsed":12,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["labels = np.minimum(labels_anshumaan, labels_saranath)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"3Yh09NRyff9L","executionInfo":{"status":"ok","timestamp":1680812605499,"user_tz":240,"elapsed":12,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["final_df = df_anshumaan.copy()\n","final_df['Label'] = labels"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"-ZR_9kXTgDWC","outputId":"87052391-a85f-4478-fa23-76bcf0e0b5ad","executionInfo":{"status":"ok","timestamp":1680812605697,"user_tz":240,"elapsed":209,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Easy-labeled problems: 53\n","Number of Difficult-labeled problems: 67\n"]}],"source":["print('Number of Easy-labeled problems: {}'.format(labels.sum()))\n","print('Number of Difficult-labeled problems: {}'.format(labels.size - labels.sum()))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"AUMrn8begopo","executionInfo":{"status":"ok","timestamp":1680812605697,"user_tz":240,"elapsed":7,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["final_df.to_csv('final_dataset.csv', index=False)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"oAGLYbOrgvcq","outputId":"436fa58f-cdaf-401d-8fc0-056a416698b0","executionInfo":{"status":"ok","timestamp":1680812605698,"user_tz":240,"elapsed":8,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Problem Description and Time Complexity required  Label\n","0           Check if a given sudoku is valid. O(N^2)      0\n","1  Merge the two lists in a one sorted list. The ...      1\n","2  Given the root of a binary tree, invert the tr...      0\n","3  Given the head of a sorted linked list, delete...      1\n","4  Given two binary strings a and b, return their...      1"],"text/html":["\n","  <div id=\"df-5e07ed37-61f0-4b24-a376-f97acb3e6c71\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Problem Description and Time Complexity required</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Check if a given sudoku is valid. O(N^2)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Merge the two lists in a one sorted list. The ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Given the root of a binary tree, invert the tr...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Given the head of a sorted linked list, delete...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Given two binary strings a and b, return their...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e07ed37-61f0-4b24-a376-f97acb3e6c71')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5e07ed37-61f0-4b24-a376-f97acb3e6c71 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5e07ed37-61f0-4b24-a376-f97acb3e6c71');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}],"source":["df = pd.read_csv('final_dataset.csv')\n","df.head(5)"]},{"cell_type":"markdown","metadata":{"id":"d23zfO_ALKeB"},"source":["# Part 2: Text classification"]},{"cell_type":"markdown","metadata":{"id":"N25dvF4jvYoy"},"source":["Now we'll move onto fine-tuning  pretrained language models specifically on your dataset. This part of the homework is meant to be an introduction to the HuggingFace library, and it contains code that will potentially be useful for your final projects. Since we're dealing with large models, the first step is to change to a GPU runtime.\n","\n","## Adding a hardware accelerator\n","\n","Please go to the menu and add a GPU as follows:\n","\n","`Edit > Notebook Settings > Hardware accelerator > (GPU)`\n","\n","Run the following cell to confirm that the GPU is detected."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"edOh9ooiIW1B","outputId":"e5b56d3e-4eea-4d60-debd-fa8d2147faa5","executionInfo":{"status":"ok","timestamp":1680812609940,"user_tz":240,"elapsed":4248,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: Tesla T4, n_gpu: 1\n"]}],"source":["import torch\n","\n","# Confirm that the GPU is detected\n","\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")"]},{"cell_type":"markdown","metadata":{"id":"xrvH7xx9LnMC"},"source":["## Installing Hugging Face's Transformers library\n","We will use Hugging Face's Transformers (https://github.com/huggingface/transformers), an open-source library that provides general-purpose architectures for natural language understanding and generation with a collection of various pretrained models made by the NLP community. This library will allow us to easily use pretrained models like `BERT` and perform experiments on top of them. We can use these models to solve downstream target tasks, such as text classification, question answering, and sequence labeling.\n","\n","Run the following cell to install Hugging Face's Transformers library and download a sample data file called tweets.csv that contains tweets about airlines along with a negative, neutral, or positive sentiment rating. Note that you will be asked to link with your Google Drive account to download some of these files. If you're concerned about security risks (there have not been any issues in previous semesters), feel free to make a new Google account and use it for this homework!"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"gtqS2e5fxpqa","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1680812640059,"user_tz":240,"elapsed":30126,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"878aa723-7e8b-4d7e-e1f0-9005feb056ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n","success!\n","helper file downloaded! (helpers.py)\n","sample tweets downloaded! (tweets.csv)\n"]}],"source":["!pip install transformers\n","!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","print('success!')\n","\n","import os\n","import zipfile\n","\n","# Download helper functions file\n","helper_file = drive.CreateFile({'id': '16HW-z9Y1tM3gZ_vFpJAuwUDohz91Aac-'})\n","helper_file.GetContentFile('helpers.py')\n","print('helper file downloaded! (helpers.py)')\n","\n","# Download sample file of tweets\n","data_file = drive.CreateFile({'id': '1QcoAmjOYRtsMX7njjQTYooIbJHPc6Ese'})\n","data_file.GetContentFile('tweets.csv')\n","print('sample tweets downloaded! (tweets.csv)')"]},{"cell_type":"markdown","metadata":{"id":"-8XIL7wPovVX"},"source":["The cell below imports some helper functions we wrote to demonstrate the task on the sample tweet dataset."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Taseb33Sovg0","executionInfo":{"status":"ok","timestamp":1680812643958,"user_tz":240,"elapsed":3907,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["from helpers import tokenize_and_format, flat_accuracy"]},{"cell_type":"markdown","metadata":{"id":"gKc0xYh-MAbc"},"source":["# Part 1: Data Prep and Model Specifications\n","\n","Upload your data using the file explorer to the left. We have provided a function below to tokenize and format your data as BERT requires. Make sure that your csv file, titled final_data.csv, has one column \"text\" and another column \"labels\" containing integers.\n","\n","If you run the cell below without modifications, it will run on the tweets.csv example data we have provided. It imports some helper functions we wrote to demonstrate the task on the sample tweet dataset. You should first run all of the following cells with tweets.csv just to see how everything works. Then, once you understand the whole preprocessing / fine-tuning process, change the csv in the below cell to your final_data.csv file, add any extra preprocessing code you wish, and then run the cells again on your own data."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252,"referenced_widgets":["a79fd31223f842fc8b0aee6ba863e672","99399d2d767e4950b313b131fb4a15d9","27eb7484a347426bb43a329de142fd05","cfb3367c20ce4fdd9412ca0d03baabb2","92af76364c5d40518cf82570fe64bba4","320882c6d32c4d05ad75e97553b36211","66b91d7387564944b89832259ca3285c","4e0ddb8a3c18452cb73e80ba03f45854","a7180039e6e44a42867176cd4aead66a","6734ada8eb0242a782a54f3f08e61cc3","23bd8fefcd5d4259b6adbbca3ed68eed","158726d564664501a691b03bdc48e36f","c659b27ade4142a7aede0400fd89a3e1","47c8344a2a1c4512b05b2316e42ebce7","e1027d5c0200409d81027df165ee127d","7452f71e41d54276bcf2a8359d48060d","478f955776c944d59e7e38f1ed590a03","c3628cc027ba4dd482eed2c4f60037d5","9ffe8c3e460d4a74840521e6d93f7783","a6c8be42b24c403495229827f88ddd8c","98f35855587c441a9cdfb0b0b56eacec","7ac2774d8c814366add2fd39bb12526b","addff15db7504479b578b7dd912374f1","5ba190547290464ca388037d9bdfd4fe","a5de48adbaf94cc9afe6091e327ab63d","9549d9dc320b4e04b4a0dae3d15f7cdc","060a04e33c544018801e080a810c9e4d","4a788ca7c9284fc1a3d1667c7fa4430a","14653b26ebd54e68b4f3f5e909ee498f","2d4dea205ac249dcb9d102a054ff5e77","e964d955bfdf4b34874b126b86142acf","3bdcde80d96349829e3890c0dbe61c0a","3a1bca34e25446d7951fffd99dccf394"]},"id":"YGhkeLQlNNr8","executionInfo":{"status":"ok","timestamp":1680812644952,"user_tz":240,"elapsed":1014,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"41db9e9f-001f-4bf9-8d22-91beb8af7eb7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a79fd31223f842fc8b0aee6ba863e672"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"158726d564664501a691b03bdc48e36f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"addff15db7504479b578b7dd912374f1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Original:  Find inorder traversal of a binary tree. O(N)\n","Token IDs: tensor([  101,  2424,  1999,  8551,  2121, 29053,  2389,  1997,  1037, 12441,\n","         3392,  1012,  1051,  1006,  1050,  1007,   102,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0])\n"]}],"source":["from helpers import tokenize_and_format, flat_accuracy\n","import pandas as pd\n","\n","df = pd.read_csv('final_dataset.csv')\n","\n","df = df.sample(frac=1).reset_index(drop=True)\n","\n","texts = df['Problem Description and Time Complexity required'].values\n","labels = df['Label'].values\n","\n","### tokenize_and_format() is a helper function provided in helpers.py ###\n","input_ids, attention_masks = tokenize_and_format(texts)\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', texts[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"0R3WOi1H6IPi","executionInfo":{"status":"ok","timestamp":1680812646134,"user_tz":240,"elapsed":1185,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["small_texts = ['Solve this with O(N^2)', 'Solve this with O(N)']\n","ids, masks = tokenize_and_format(small_texts)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"nxjJccMm6YQU","executionInfo":{"status":"ok","timestamp":1680812646134,"user_tz":240,"elapsed":19,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"aa279eb1-4816-407e-cc71-200b8ef19e3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Solve this with O(N^2)\n","tensor([[ 101, 9611, 2023, 2007, 1051, 1006, 1050, 1034, 1016, 1007,  102,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0]])\n"]}],"source":["print(small_texts[0])\n","print(ids[0])\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"Zkk4PXRg6fc_","executionInfo":{"status":"ok","timestamp":1680812646135,"user_tz":240,"elapsed":17,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"cfec349e-f2d1-4305-9e28-8f64aa43b2e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Solve this with O(N)\n","tensor([[ 101, 9611, 2023, 2007, 1051, 1006, 1050, 1007,  102,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0]])\n"]}],"source":["print(small_texts[1])\n","print(ids[1])"]},{"cell_type":"markdown","metadata":{"id":"H3D-CzQEUXYz"},"source":["## Create train/test/validation splits\n","\n","Here we split your dataset into 3 parts: a training set, a validation set, and a testing set. Each item in your dataset will be a 3-tuple containing an input_id tensor, an attention_mask tensor, and a label tensor.\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"kGgeZ3M0UWs0","executionInfo":{"status":"ok","timestamp":1680812646136,"user_tz":240,"elapsed":15,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["total = len(df)\n","\n","num_train = int(total * .8)\n","num_val = int(total * .1)\n","num_test = total - num_train - num_val\n","\n","# make lists of 3-tuples (already shuffled the dataframe in cell above)\n","\n","train_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train)]\n","val_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train, num_val+num_train)]\n","test_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_val + num_train, total)]\n","\n","train_text = [texts[i] for i in range(num_train)]\n","val_text = [texts[i] for i in range(num_train, num_val+num_train)]\n","test_text = [texts[i] for i in range(num_val + num_train, total)]\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"GHpGKsXEkcvK","executionInfo":{"status":"ok","timestamp":1680812646136,"user_tz":240,"elapsed":14,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"c9391812-e084-464d-ba1a-9b4f0b6f1283"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train data: 96\n","Val data: 12\n","Test data: 12\n"]}],"source":["print('Train data: {}'.format(len(train_text)))\n","print('Val data: {}'.format(len(val_text)))\n","print('Test data: {}'.format(len(test_text)))"]},{"cell_type":"markdown","metadata":{"id":"QCr006iTkqwM"},"source":["Here we choose the model we want to finetune from https://huggingface.co/transformers/pretrained_models.html. Because the task requires us to label sentences, we wil be using BertForSequenceClassification below. You may see a warning that states that `some weights of the model checkpoint at [model name] were not used when initializing. . .` This warning is expected and means that you should fine-tune your pre-trained model before using it on your downstream task. See [here](https://github.com/huggingface/transformers/issues/5421#issuecomment-652582854) for more info."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"lPo640_ZlEPK","executionInfo":{"status":"ok","timestamp":1680812646137,"user_tz":240,"elapsed":12,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# model = BertForSequenceClassification.from_pretrained(\n","#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","#     num_labels = 2, # The number of output labels.   \n","#     output_attentions = False, # Whether the model returns attentions weights.\n","#     output_hidden_states = False, # Whether the model returns all hidden-states.\n","# )\n","\n","# # Tell pytorch to run this model on the GPU.\n","# model.cuda()\n"]},{"cell_type":"markdown","metadata":{"id":"i3lLdoW_le3M"},"source":["# ACTION REQUIRED #\n","\n","Define your fine-tuning hyperparameters in the cell below (we have randomly picked some values to start with). We want you to experiment with different configurations to find the one that works best (i.e., highest accuracy) on your validation set. Feel free to also change pretrained models to others available in the HuggingFace library (you'll have to modify the cell above to do this). You might find papers on BERT fine-tuning stability (e.g., [Mosbach et al., ICLR 2021](https://openreview.net/pdf?id=nzpLWnVAyah)) to be of interest."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"poQgjb4k6eUj","executionInfo":{"status":"ok","timestamp":1680812646137,"user_tz":240,"elapsed":10,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["import random"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"Dd2JdC6IletV","executionInfo":{"status":"ok","timestamp":1680812646138,"user_tz":240,"elapsed":10,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["# batch_size = 99\n","# optimizer = AdamW(model.parameters(),\n","#                   lr = 5e-5, # args.learning_rate - default is 5e-5\n","#                   eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n","#                 )\n"]},{"cell_type":"markdown","metadata":{"id":"Pd4fwn_el1ge"},"source":["# Fine-tune your model\n","Here we provide code for fine-tuning your model, monitoring the loss, and checking your validation accuracy. Rerun both of the below cells when you change your hyperparameters above."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"O_Mzr-kd5RaY","executionInfo":{"status":"ok","timestamp":1680812646327,"user_tz":240,"elapsed":198,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["import numpy as np\n","# function to get validation accuracy\n","def get_validation_performance(model, val_set, batch_size, output_labels=True):\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","\n","    num_batches = int(len(val_set)/batch_size) + 1\n","\n","    total_correct = 0\n","\n","    for i in range(num_batches):\n","\n","      end_index = min(batch_size * (i+1), len(val_set))\n","\n","      batch = val_set[i*batch_size:end_index]\n","      \n","      if len(batch) == 0: continue\n","\n","      input_id_tensors = torch.stack([data[0] for data in batch])\n","      input_mask_tensors = torch.stack([data[1] for data in batch])\n","      label_tensors = torch.stack([data[2] for data in batch])\n","      \n","      # Move tensors to the GPU\n","      b_input_ids = input_id_tensors.to(device)\n","      b_input_mask = input_mask_tensors.to(device)\n","      b_labels = label_tensors.to(device)\n","        \n","      # Tell pytorch not to bother with constructing the compute graph during\n","      # the forward pass, since this is only needed for backprop (training).\n","      with torch.no_grad():        \n","\n","        # Forward pass, calculate logit predictions.\n","        outputs = model(b_input_ids, \n","                                token_type_ids=None, \n","                                attention_mask=b_input_mask,\n","                                labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","        \n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the number of correctly labeled examples in batch\n","        pred_flat = np.argmax(logits, axis=1).flatten()\n","        labels_flat = label_ids.flatten()\n","        num_correct = np.sum(pred_flat == labels_flat)\n","        total_correct += num_correct\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_correct / len(val_set)\n","\n","    return (avg_val_accuracy, pred_flat, labels_flat) if output_labels else avg_val_accuracy\n","\n"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"HTf_ipbjWNoV","executionInfo":{"status":"ok","timestamp":1680812646328,"user_tz":240,"elapsed":12,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"outputs":[],"source":["# training loop\n","\n","def train(model, batch_size, lr):\n","  loss_history = [] \n","  vals_history = []\n","  print('============== SUMMARY =================')\n","  print('batch_size: {} and lr: {}'.format(batch_size, lr))\n","  optimizer = AdamW(model.parameters(),\n","                    lr = lr,\n","                    eps = 1e-8) # use the default value\n","\n","  # For each epoch...\n","  for epoch_i in range(0, epochs):\n","      # Perform one full pass over the training set.\n","      if epoch_i % 5 == 0:\n","        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","\n","      # Reset the total loss for this epoch.\n","      total_train_loss = 0\n","\n","      # Put the model into training mode.\n","      model.train()\n","\n","      # For each batch of training data...\n","      num_batches = int(len(train_set)/batch_size) + 1\n","\n","      for i in range(num_batches):\n","        end_index = min(batch_size * (i+1), len(train_set))\n","\n","        batch = train_set[i*batch_size:end_index]\n","\n","        if len(batch) == 0: continue\n","\n","        input_id_tensors = torch.stack([data[0] for data in batch])\n","        input_mask_tensors = torch.stack([data[1] for data in batch])\n","        label_tensors = torch.stack([data[2] for data in batch])\n","\n","        # Move tensors to the GPU\n","        b_input_ids = input_id_tensors.to(device)\n","        b_input_mask = input_mask_tensors.to(device)\n","        b_labels = label_tensors.to(device)\n","\n","        # Clear the previously calculated gradient\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        outputs = model(b_input_ids, \n","                              token_type_ids=None, \n","                              attention_mask=b_input_mask, \n","                              labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Update parameters and take a step using the computed gradient.\n","        optimizer.step()\n","          \n","      # ========================================\n","      #               Validation\n","      # ========================================\n","      # After the completion of each training epoch, measure our performance on\n","      # our validation set. Implement this function in the cell above.\n","      \n","      val_acc = get_validation_performance(model, val_set, batch_size, output_labels=False)\n","\n","      if epoch_i % 5 == 0:\n","        print(f\"Total loss: {total_train_loss}\")\n","        print(f\"Validation accuracy: {val_acc}\")\n","\n","      # Record this these values to stats\n","      loss_history.append(total_train_loss)\n","      vals_history.append(val_acc)\n","      \n","  print(\"\")\n","  print(\"Training complete!\")\n","  print('========================================')\n","  return loss_history, vals_history"]},{"cell_type":"code","source":["SEED = 10\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# HYPERPARAMETERS TUNING\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","batches = [8, 16] \n","lrs = [5e-5, 3e-4, 5e-4, 2e-5]\n","epochs = 20\n","\n","# Record the hyperparameters stats\n","stats = {}\n","\n","for batch_size in batches:\n","  for lr in lrs:\n","    # Initialize new model for this set of hyperparameters\n","    model = BertForSequenceClassification.from_pretrained(\n","              \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","              num_labels = 2, # The number of output labels.   \n","              output_attentions = False, # Whether the model returns attentions weights.\n","              output_hidden_states = False # Whether the model returns all hidden-states.\n","    )\n","\n","    # Tell pytorch to run this model on the GPU.\n","    model.cuda()\n","\n","    loss_history, vals_history = train(model, batch_size, lr)\n","    \n","    # Record the training info\n","    stats[(str(batch_size), str(lr))] = {\n","        'loss_history': loss_history,\n","        'vals_history': vals_history,\n","        'model': model\n","    }\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"I8bcVECQYltQ","outputId":"8c4d5a2a-c2e9-421a-9228-a6eacc213397","executionInfo":{"status":"ok","timestamp":1680812920359,"user_tz":240,"elapsed":220169,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}}},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["============== SUMMARY =================\n","batch_size: 8 and lr: 5e-05\n","======== Epoch 1 / 20 ========\n","Total loss: 8.455386579036713\n","Validation accuracy: 0.75\n","======== Epoch 6 / 20 ========\n","Total loss: 0.48825080320239067\n","Validation accuracy: 0.6666666666666666\n","======== Epoch 11 / 20 ========\n","Total loss: 0.07995813572779298\n","Validation accuracy: 0.75\n","======== Epoch 16 / 20 ========\n","Total loss: 0.021651839138939977\n","Validation accuracy: 0.75\n","\n","Training complete!\n","========================================\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["============== SUMMARY =================\n","batch_size: 8 and lr: 0.0003\n","======== Epoch 1 / 20 ========\n","Total loss: 8.968421041965485\n","Validation accuracy: 0.3333333333333333\n","======== Epoch 6 / 20 ========\n","Total loss: 8.847973942756653\n","Validation accuracy: 0.6666666666666666\n","======== Epoch 11 / 20 ========\n","Total loss: 8.593302726745605\n","Validation accuracy: 0.3333333333333333\n","======== Epoch 16 / 20 ========\n","Total loss: 8.139609515666962\n","Validation accuracy: 0.3333333333333333\n","\n","Training complete!\n","========================================\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["============== SUMMARY =================\n","batch_size: 8 and lr: 0.0005\n","======== Epoch 1 / 20 ========\n","Total loss: 9.23914086818695\n","Validation accuracy: 0.3333333333333333\n","======== Epoch 6 / 20 ========\n","Total loss: 8.475567936897278\n","Validation accuracy: 0.6666666666666666\n","======== Epoch 11 / 20 ========\n","Total loss: 8.492884993553162\n","Validation accuracy: 0.6666666666666666\n","======== Epoch 16 / 20 ========\n","Total loss: 8.346251547336578\n","Validation accuracy: 0.3333333333333333\n","\n","Training complete!\n","========================================\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["============== SUMMARY =================\n","batch_size: 8 and lr: 2e-05\n","======== Epoch 1 / 20 ========\n","Total loss: 8.734650254249573\n","Validation accuracy: 0.6666666666666666\n","======== Epoch 6 / 20 ========\n","Total loss: 4.188690587878227\n","Validation accuracy: 0.8333333333333334\n","======== Epoch 11 / 20 ========\n","Total loss: 0.5903674270957708\n","Validation accuracy: 0.6666666666666666\n","======== Epoch 16 / 20 ========\n","Total loss: 0.4838828481733799\n","Validation accuracy: 0.75\n","\n","Training complete!\n","========================================\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["============== SUMMARY =================\n","batch_size: 16 and lr: 5e-05\n","======== Epoch 1 / 20 ========\n","Total loss: 4.255751669406891\n","Validation accuracy: 0.3333333333333333\n","======== Epoch 6 / 20 ========\n","Total loss: 1.1706599444150925\n","Validation accuracy: 0.5\n","======== Epoch 11 / 20 ========\n","Total loss: 0.05376311577856541\n","Validation accuracy: 0.75\n","======== Epoch 16 / 20 ========\n","Total loss: 0.008505233097821474\n","Validation accuracy: 0.75\n","\n","Training complete!\n","========================================\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["============== SUMMARY =================\n","batch_size: 16 and lr: 0.0003\n","======== Epoch 1 / 20 ========\n","Total loss: 4.484924077987671\n","Validation accuracy: 0.6666666666666666\n","======== Epoch 6 / 20 ========\n","Total loss: 3.7814935743808746\n","Validation accuracy: 0.5833333333333334\n","======== Epoch 11 / 20 ========\n","Total loss: 3.3153975307941437\n","Validation accuracy: 0.75\n","======== Epoch 16 / 20 ========\n","Total loss: 2.279431074857712\n","Validation accuracy: 0.75\n","\n","Training complete!\n","========================================\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["============== SUMMARY =================\n","batch_size: 16 and lr: 0.0005\n","======== Epoch 1 / 20 ========\n","Total loss: 5.2882009744644165\n","Validation accuracy: 0.6666666666666666\n","======== Epoch 6 / 20 ========\n","Total loss: 4.319079756736755\n","Validation accuracy: 0.3333333333333333\n","======== Epoch 11 / 20 ========\n","Total loss: 4.237077832221985\n","Validation accuracy: 0.6666666666666666\n","======== Epoch 16 / 20 ========\n","Total loss: 4.335301399230957\n","Validation accuracy: 0.6666666666666666\n","\n","Training complete!\n","========================================\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["============== SUMMARY =================\n","batch_size: 16 and lr: 2e-05\n","======== Epoch 1 / 20 ========\n","Total loss: 4.258793354034424\n","Validation accuracy: 0.6666666666666666\n","======== Epoch 6 / 20 ========\n","Total loss: 2.1990422308444977\n","Validation accuracy: 0.75\n","======== Epoch 11 / 20 ========\n","Total loss: 0.4784640520811081\n","Validation accuracy: 0.6666666666666666\n","======== Epoch 16 / 20 ========\n","Total loss: 0.11986791156232357\n","Validation accuracy: 0.6666666666666666\n","\n","Training complete!\n","========================================\n"]}]},{"cell_type":"markdown","metadata":{"id":"J9DpRJE5mHkO"},"source":["# Evaluate your model on the test set\n","After you're satisfied with your hyperparameters (i.e., you're unable to achieve higher validation accuracy by modifying them further), it's time to evaluate your model on the test set! Run the below cell to compute test set accuracy.\n"]},{"cell_type":"markdown","source":["As we can see there are multiple models with different hyperparameters that give same validation accuracy of $0.75$. Therefore, we will see all the test accuracy among all models and decide which one is the best. "],"metadata":{"id":"150W1PhohMkT"}},{"cell_type":"code","execution_count":30,"metadata":{"id":"msvZ78ii3cZZ","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1680812926506,"user_tz":240,"elapsed":203,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"dc560b50-f91c-43c9-8c49-4f98e99bb51f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6666666666666666"]},"metadata":{},"execution_count":30}],"source":["batch_size, lr = 16, 5e-5\n","model = stats[(str(batch_size), str(lr))]['model']\n","get_validation_performance(model, test_set, len(test_set), output_labels=False)"]},{"cell_type":"markdown","metadata":{"id":"IcMT5aih8xEb"},"source":["## Question 2.1 (10 points):\n","Congratulations! You've now gone through the entire fine-tuning process and created a model for your downstream task. Two more questions left :) First, describe your hyperparameter selection process in words. If you based your process on any research papers or websites, please reference them. Why do you think the hyperparameters you ended up choosing worked better than others? Also, is there a significant discrepancy between your test and validation accuracy? Why do you think this is the case?\n","\n","\n"]},{"cell_type":"code","source":["print('======== Test Set =========')\n","for text in test_text:\n","  print(text)\n","print('')\n","print('======== Validation Set =========')\n","for text in val_text:\n","  print(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"bRi9JKYxUDgq","executionInfo":{"status":"ok","timestamp":1680813887674,"user_tz":240,"elapsed":180,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"53815590-3473-4a50-e200-414964e577dd"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["======== Test Set =========\n","Given a string s, return the number of substrings that have only one distinct letter. O(N^3)\n","Given the head of a singly linked list, return true if it is a palindrome or false otherwise. O(N)\n","Given a string s containing just the characters '(', ')', '{', '}', '[' and ']', determine if the input string is valid.\n","    Every close bracket has a corresponding open bracket of the same type. O(N)\n","Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.\n","    You may assume that each input would have exactly one solution, and you may not use the same element twice.\n","    You can return the answer in any order. O(N)\n","Given an integer n, return any array containing n unique integers such that they add up to 0. O(N)\n","Check if a given sudoku is valid. O(N^2)\n","Given the head of a singly linked list, group all the nodes with odd indices together followed by the nodes with even indices, and return the reordered list.\n","    The first node is considered odd, and the second node is even, and so on. O(N)\n","Given an array of integers arr, find the sum of min(b), where b ranges over every (contiguous) subarray of arr. O(N)\n","Given a linked list, swap every two adjacent nodes and return its head. You must solve the problem without modifying the values in the list's nodes (i.e., only nodes themselves may be changed.). O(N)\n","Given an integer array nums, find the subarray with the largest sum, and return its sum. O(N)\n","Given an integer array nums, return true if any value appears at least twice in the array, and return false if every element is distinct. O(N)\n","Given an array of points where points[i] = [xi, yi] represents a point on the X-Y plane and an integer k, return the k closest points to the origin (0, 0).\n","    The distance between two points on the X-Y plane is the Euclidean distance. O(NlogK)\n","\n","======== Validation Set =========\n","Given an array of integers nums sorted in non-decreasing order, find the starting and ending position of a given target value.\n","    If target is not found in the array, return [-1, -1]. O(logN)\n","Given an integer array nums, return an array answer such that answer[i] is equal to the product of all the elements of nums except nums[i]. O(N)\n","Find a target number in an sorted array. O(logN)\n","Given a m x n grid filled with non-negative numbers, find a path from top left to bottom right, which minimizes the sum of all numbers along its path.\n","    Note: You can only move either down or right at any point in time. O(N^2)\n","You are given an integer array nums. The range of a subarray of nums is the difference between the largest and smallest element in the subarray.\n","    Return the sum of all subarray ranges of nums. O(N)\n","Given an array of integers nums, find the maximum length of a subarray where the product of all its elements is positive.\n","    A subarray of an array is a consecutive sequence of zero or more values taken out of that array. Return the maximum length of a subarray with positive product. O(N)\n","Given two binary strings a and b, return their sum as a binary string. O(N)\n","Given two non-negative integers, num1 and num2 represented as string, return the sum of num1 and num2 as a string. O(N)\n","You are given an array of integers nums, there is a sliding window of size k which is moving from the very left of the array to the very right. You can only see the k numbers in the window. Each time the sliding window moves right by one position.\n","    Return the max sliding window. O(N)\n","Given a 2D matrix, return its transpose. O(N^2)\n","Given the head of a singly linked list, return the middle node of the linked list. If there are two middle nodes, return the second middle node. O(N)\n","A string can be abbreviated by replacing any number of non-adjacent, non-empty substrings with their lengths. The lengths should not have leading zeros.\n","    Given a string word and an abbreviation abbr, return whether the string matches the given abbreviation.\n","    A substring is a contiguous non-empty sequence of characters within a string. O(N)\n"]}]},{"cell_type":"markdown","source":["### *WRITE YOUR ANSWER HERE*\n","\n","My choice of hyperparameters are taken directly from the recommended paper. In that paper they were finetuning uncased BERT model with batch size of 16 and learning rate of 2e-5. Since our model is trained on a very small dataset, it is very easy for the model to overfit the data. Thus some learning rates in addition are not too far away from 2e-5 are used to train the model. Furthermore, following the same reason I chose to train on small batch size instead of full batch size because according to the authors of “On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima,” tend to result in models that become caught in local minima.\n","\n","By observations, the test accuracies are not very useful. The models are not performning so good on the test set, i.e it is no better than tossing a fair coin. By looking at the validation histories of all the models, we tend to see that they are either overfits or stuck at local minima. Another interesting observations that it seems initialized hidden states are also important while training the model. This might be due to the nature of the chosen classification problem. I believe that more preprocessings should be done to the input so that the model will efficiently capture embeddings of the input and therefore be able to learn the task better. \n","\n","\\\\\n","Therefore, by looking at the training process it is very hard to determine if the model is actually learning the **pattern** that we want despite by looking at the problem descriptions from both validation set and test text, we do see that there is not much of a discrepancy between them as all problems are common data structures and algorithms."],"metadata":{"id":"vT_AUVNFUGAI"}},{"cell_type":"markdown","metadata":{"id":"NBbdMwt79fIs"},"source":["## Question 2.2 (20 points):\n","Finally, perform an *error analysis* on your model. This is good practice for your final project. Write some code in the below code cell to print out the text of up to five test set examples that your model gets **wrong**. If your model gets more than five test examples wrong, randomly choose five of them to analyze. If your model gets fewer than five examples wrong, please design five test examples that fool your model (i.e., *adversarial examples*). Then, in the following text cell, perform a qualitative analysis of these examples. See if you can figure out any reasons for errors that you observe, or if you have any informed guesses (e.g., common linguistic properties of these particular examples). Does this analysis suggest any possible future steps to improve your classifier?"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"X72mumhI9WdR","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1680812986836,"user_tz":240,"elapsed":140,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"935c2bda-f40b-44de-fe86-a91baae3d0c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.6666666666666666\n","Predicted labels: [0 1 0 1 1 0 1 0 0 0 1 1]\n","Test labels: [0 0 0 0 0 0 1 0 0 0 1 0]\n"]}],"source":["## YOUR ERROR ANALYSIS CODE HERE\n","## print out up to 5 test set examples (or adversarial examples) that your model gets wrong\n","\n","test_acc, pred_y, test_y = get_validation_performance(model, test_set, len(test_set), output_labels=True) \n","print('Test Accuracy: {}'.format(test_acc))\n","print('Predicted labels: {}'.format(pred_y))\n","print('Test labels: {}'.format(test_y))"]},{"cell_type":"code","source":["count = 0\n","for i in range(len(test_y)):\n","  if pred_y[i] != test_y[i]:\n","    print('Problem: {}, Predicted: {}, Label: {}'.format(test_text[i], pred_y[i], test_y[i]))\n","    count += 1\n","    if count == 5: break"],"metadata":{"id":"NsZA3DPKprIs","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1680813615522,"user_tz":240,"elapsed":185,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"79056391-4eaf-45ce-f3a0-f154c54d1228"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Problem: Given the head of a singly linked list, return true if it is a palindrome or false otherwise. O(N), Predicted: 1, Label: 0\n","Problem: Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.\n","    You may assume that each input would have exactly one solution, and you may not use the same element twice.\n","    You can return the answer in any order. O(N), Predicted: 1, Label: 0\n","Problem: Given an integer n, return any array containing n unique integers such that they add up to 0. O(N), Predicted: 1, Label: 0\n","Problem: Given an array of points where points[i] = [xi, yi] represents a point on the X-Y plane and an integer k, return the k closest points to the origin (0, 0).\n","    The distance between two points on the X-Y plane is the Euclidean distance. O(NlogK), Predicted: 1, Label: 0\n"]}]},{"cell_type":"code","source":["for i in range(len(test_y)):\n","  if pred_y[i] == test_y[i]:\n","    print(test_text[i], pred_y[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"nbZpuylcSghZ","executionInfo":{"status":"ok","timestamp":1680813512127,"user_tz":240,"elapsed":149,"user":{"displayName":"Quoc Anh H Bui","userId":"11232193766686747605"}},"outputId":"ecbb258a-3565-4ce2-e617-a2e6ed64c899"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Given a string s, return the number of substrings that have only one distinct letter. O(N^3) 0\n","Given a string s containing just the characters '(', ')', '{', '}', '[' and ']', determine if the input string is valid.\n","    Every close bracket has a corresponding open bracket of the same type. O(N) 0\n","Check if a given sudoku is valid. O(N^2) 0\n","Given the head of a singly linked list, group all the nodes with odd indices together followed by the nodes with even indices, and return the reordered list.\n","    The first node is considered odd, and the second node is even, and so on. O(N) 1\n","Given an array of integers arr, find the sum of min(b), where b ranges over every (contiguous) subarray of arr. O(N) 0\n","Given a linked list, swap every two adjacent nodes and return its head. You must solve the problem without modifying the values in the list's nodes (i.e., only nodes themselves may be changed.). O(N) 0\n","Given an integer array nums, find the subarray with the largest sum, and return its sum. O(N) 0\n","Given an integer array nums, return true if any value appears at least twice in the array, and return false if every element is distinct. O(N) 1\n"]}]},{"cell_type":"markdown","source":["Again, same conclusion from 2.1 we cannot hardly determine if the model is looking at the same thing that the annotators do when look at the problem description and time complexity. Therefore, there is a great difference between the model's predictions and annotators' labels. This behavior is understanable since it could be that annotators weights the factor of time complexity more than model. Another example could be annotators have more experience working with these coding problems, i.e similar problem but different data structure was given would affect differently on the difficulty of the problem etc. Meanwhile, it is possible that the model learns only from the wordings of the problem.\n","\n","\\\\\n","In conclusion, due to the limited dataset, the model probably has limited knowledge about what is the critical part in determining the difficulty of the problem given. Therefore, next step I would include:\n","* More dataset.\n","* Better preprocessing: This include better ways of encodings for time complexity required, data structures, algorithms, possible patterns that could be used to solve the problem. By doing this, we would be able to force the model to pay a lot more attention on these factors than the wording of the problems itself.\n","\n","* More annotators: One factor I did not consider is my annotators' expertise in solving these LC-styled coding problems. A person who never solve leetcode problems before would find the majority of these problems very difficult."],"metadata":{"id":"BgPzcU0Wf__n"}},{"cell_type":"markdown","metadata":{"id":"6XyBdAup-e6Z"},"source":["### *DESCRIBE YOUR QUALITATIVE ANALYSIS OF THE ABOVE EXAMPLES HERE*"]},{"cell_type":"markdown","metadata":{"id":"szIkBDiQ_Mkv"},"source":["\n","\n","---\n","\n","Finished? Remember to upload the PDF file of this notebook to Gradescope **AND** email your three dataset files (annotator1.csv, annotator2.csv, and final_data.csv) to cs685instructors@gmail.com with the subject line formatted as **Firstname_Lastname_HW1data**.\n"]},{"cell_type":"markdown","metadata":{"id":"w6L1RySHhf7v"},"source":["## AI Disclosure\n","\n","*   Did you use any AI assistance to complete this homework? If so, please also specify what AI you used.\n","    * NO\n","\n","\n","---\n","*(only complete the below questions if you answered yes above)*\n","\n","*   If you used a large language model to assist you, please paste *all* of the prompts that you used below. Add a separate bullet for each prompt, and specify which problem is associated with which prompt.\n","    * *your response here*\n","*   **Free response**: For each problem for which you used assistance, describe your overall experience with the AI. How helpful was it? Did it just directly give you a good answer, or did you have to edit it? Was its output ever obviously wrong or irrelevant? Did you use it to get the answer or check your own answer? \n","    * *your response here*\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["SgNZTjrhcHa0"],"provenance":[{"file_id":"1Q3Ck1g1PvzShG08Ubwq-r7iffgzoV7Y5","timestamp":1680649304093},{"file_id":"1K-yEsHe9c4B6vBiL24t91BCovRN5ZP1a","timestamp":1678483644634},{"file_id":"1qWfGHzKDt2o0AuFEDJB3FAg_J6GE52nG","timestamp":1646435194169},{"file_id":"1Sl6tl-dL32oI5gEcofa-9Orjh9BWQkB7","timestamp":1646435132542},{"file_id":"12lyhUy6ZAN2BO8lCOUrdLG7cxkD2KrB4","timestamp":1646253268722},{"file_id":"1cTDpMUuJbxxaGEcNe11KQXLLweu8OA8r","timestamp":1646026402023},{"file_id":"1CRZfedkwWd5_NAIVp1vo6bz5xYkyTFgC","timestamp":1634149359597},{"file_id":"1K9H753cX0tD0lsoXvyHsDhrTtbnzq1bL","timestamp":1603002079306},{"file_id":"18v_7cFNT362Lzcmyg_PNKVnGQgVKc3i2","timestamp":1602459467767},{"file_id":"1bcAXWjkz8V8PK1FhnBrsb5YZAHKJiVFe","timestamp":1601580687210},{"file_id":"1wgo33YMqyTmwPXBCgDYvDD39Hgz516zV","timestamp":1599667757648},{"file_id":"1ZNQQshRjVp-0vLNi6ZGRtXX102EWHRq4","timestamp":1598302241860},{"file_id":"1XOa--UHuAQpBRcdqYbFcb8QuUTvywsSk","timestamp":1568522504552},{"file_id":"1LShMg_-e2SzrjDMxSgVbnYyTAgwcJov0","timestamp":1568420694683}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a79fd31223f842fc8b0aee6ba863e672":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99399d2d767e4950b313b131fb4a15d9","IPY_MODEL_27eb7484a347426bb43a329de142fd05","IPY_MODEL_cfb3367c20ce4fdd9412ca0d03baabb2"],"layout":"IPY_MODEL_92af76364c5d40518cf82570fe64bba4"}},"99399d2d767e4950b313b131fb4a15d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_320882c6d32c4d05ad75e97553b36211","placeholder":"​","style":"IPY_MODEL_66b91d7387564944b89832259ca3285c","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"27eb7484a347426bb43a329de142fd05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e0ddb8a3c18452cb73e80ba03f45854","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7180039e6e44a42867176cd4aead66a","value":231508}},"cfb3367c20ce4fdd9412ca0d03baabb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6734ada8eb0242a782a54f3f08e61cc3","placeholder":"​","style":"IPY_MODEL_23bd8fefcd5d4259b6adbbca3ed68eed","value":" 232k/232k [00:00&lt;00:00, 3.29MB/s]"}},"92af76364c5d40518cf82570fe64bba4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"320882c6d32c4d05ad75e97553b36211":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66b91d7387564944b89832259ca3285c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e0ddb8a3c18452cb73e80ba03f45854":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7180039e6e44a42867176cd4aead66a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6734ada8eb0242a782a54f3f08e61cc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23bd8fefcd5d4259b6adbbca3ed68eed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"158726d564664501a691b03bdc48e36f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c659b27ade4142a7aede0400fd89a3e1","IPY_MODEL_47c8344a2a1c4512b05b2316e42ebce7","IPY_MODEL_e1027d5c0200409d81027df165ee127d"],"layout":"IPY_MODEL_7452f71e41d54276bcf2a8359d48060d"}},"c659b27ade4142a7aede0400fd89a3e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_478f955776c944d59e7e38f1ed590a03","placeholder":"​","style":"IPY_MODEL_c3628cc027ba4dd482eed2c4f60037d5","value":"Downloading (…)okenizer_config.json: 100%"}},"47c8344a2a1c4512b05b2316e42ebce7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ffe8c3e460d4a74840521e6d93f7783","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6c8be42b24c403495229827f88ddd8c","value":28}},"e1027d5c0200409d81027df165ee127d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98f35855587c441a9cdfb0b0b56eacec","placeholder":"​","style":"IPY_MODEL_7ac2774d8c814366add2fd39bb12526b","value":" 28.0/28.0 [00:00&lt;00:00, 1.01kB/s]"}},"7452f71e41d54276bcf2a8359d48060d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"478f955776c944d59e7e38f1ed590a03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3628cc027ba4dd482eed2c4f60037d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ffe8c3e460d4a74840521e6d93f7783":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6c8be42b24c403495229827f88ddd8c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98f35855587c441a9cdfb0b0b56eacec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ac2774d8c814366add2fd39bb12526b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"addff15db7504479b578b7dd912374f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ba190547290464ca388037d9bdfd4fe","IPY_MODEL_a5de48adbaf94cc9afe6091e327ab63d","IPY_MODEL_9549d9dc320b4e04b4a0dae3d15f7cdc"],"layout":"IPY_MODEL_060a04e33c544018801e080a810c9e4d"}},"5ba190547290464ca388037d9bdfd4fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a788ca7c9284fc1a3d1667c7fa4430a","placeholder":"​","style":"IPY_MODEL_14653b26ebd54e68b4f3f5e909ee498f","value":"Downloading (…)lve/main/config.json: 100%"}},"a5de48adbaf94cc9afe6091e327ab63d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d4dea205ac249dcb9d102a054ff5e77","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e964d955bfdf4b34874b126b86142acf","value":570}},"9549d9dc320b4e04b4a0dae3d15f7cdc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bdcde80d96349829e3890c0dbe61c0a","placeholder":"​","style":"IPY_MODEL_3a1bca34e25446d7951fffd99dccf394","value":" 570/570 [00:00&lt;00:00, 28.9kB/s]"}},"060a04e33c544018801e080a810c9e4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a788ca7c9284fc1a3d1667c7fa4430a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14653b26ebd54e68b4f3f5e909ee498f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d4dea205ac249dcb9d102a054ff5e77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e964d955bfdf4b34874b126b86142acf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3bdcde80d96349829e3890c0dbe61c0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a1bca34e25446d7951fffd99dccf394":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}